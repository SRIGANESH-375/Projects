{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqUGDB2bWR6X1hwcThkqNJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SRIGANESH-375/Projects/blob/main/Untitled8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkBhgKzSNPFS",
        "outputId": "c5efa73b-1bee-47b8-9207-0d1b639da4ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Epoch 1/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.1458 - loss: 19.8613 - val_accuracy: 0.0833 - val_loss: 12.8697\n",
            "Epoch 2/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - accuracy: 0.1458 - loss: 19.4094 - val_accuracy: 0.1667 - val_loss: 19.1255\n",
            "Epoch 3/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step - accuracy: 0.1250 - loss: 31.5063 - val_accuracy: 0.0000e+00 - val_loss: 24.6734\n",
            "Epoch 4/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.1458 - loss: 35.8594 - val_accuracy: 0.0000e+00 - val_loss: 25.3947\n",
            "Epoch 5/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - accuracy: 0.0833 - loss: 33.9657 - val_accuracy: 0.2500 - val_loss: 16.3811\n",
            "Epoch 6/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.1250 - loss: 22.1240 - val_accuracy: 0.0833 - val_loss: 25.3416\n",
            "Epoch 7/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.1458 - loss: 26.0040 - val_accuracy: 0.0833 - val_loss: 18.8286\n",
            "Epoch 8/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.1458 - loss: 18.6952 - val_accuracy: 0.1667 - val_loss: 11.4133\n",
            "Epoch 9/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.1250 - loss: 12.8164 - val_accuracy: 0.1667 - val_loss: 6.5817\n",
            "Epoch 10/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.2083 - loss: 8.1045 - val_accuracy: 0.2500 - val_loss: 5.7866\n",
            "Epoch 11/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.1875 - loss: 7.6398 - val_accuracy: 0.0833 - val_loss: 7.3794\n",
            "Epoch 12/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.2083 - loss: 8.4484 - val_accuracy: 0.0833 - val_loss: 7.8854\n",
            "Epoch 13/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.1875 - loss: 8.6465 - val_accuracy: 0.0000e+00 - val_loss: 6.3589\n",
            "Epoch 14/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.1875 - loss: 7.0050 - val_accuracy: 0.1667 - val_loss: 7.0510\n",
            "Epoch 15/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.1458 - loss: 7.7560 - val_accuracy: 0.0000e+00 - val_loss: 5.8960\n",
            "Epoch 16/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.1042 - loss: 5.9963 - val_accuracy: 0.1667 - val_loss: 5.3725\n",
            "Epoch 17/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.1667 - loss: 4.9468 - val_accuracy: 0.1667 - val_loss: 3.2170\n",
            "Epoch 18/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.2083 - loss: 2.8510 - val_accuracy: 0.2500 - val_loss: 3.7670\n",
            "Epoch 19/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.1458 - loss: 4.2688 - val_accuracy: 0.2500 - val_loss: 3.2098\n",
            "Epoch 20/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.1875 - loss: 3.4561 - val_accuracy: 0.0833 - val_loss: 5.1128\n",
            "Epoch 21/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.1458 - loss: 4.8939 - val_accuracy: 0.0833 - val_loss: 4.4366\n",
            "Epoch 22/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.1458 - loss: 4.0638 - val_accuracy: 0.0833 - val_loss: 3.3009\n",
            "Epoch 23/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.1875 - loss: 3.1911 - val_accuracy: 0.0833 - val_loss: 3.1443\n",
            "Epoch 24/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.2083 - loss: 3.3534 - val_accuracy: 0.0000e+00 - val_loss: 2.8905\n",
            "Epoch 25/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.3125 - loss: 3.2595 - val_accuracy: 0.1667 - val_loss: 2.6166\n",
            "Epoch 26/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.2708 - loss: 2.8767 - val_accuracy: 0.2500 - val_loss: 2.4666\n",
            "Epoch 27/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.3750 - loss: 2.4796 - val_accuracy: 0.1667 - val_loss: 2.7184\n",
            "Epoch 28/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 0.2083 - loss: 2.5974 - val_accuracy: 0.1667 - val_loss: 2.4823\n",
            "Epoch 29/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.2500 - loss: 2.2976 - val_accuracy: 0.1667 - val_loss: 2.1824\n",
            "Epoch 30/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.4375 - loss: 2.0254 - val_accuracy: 0.2500 - val_loss: 2.2118\n",
            "Epoch 31/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.2917 - loss: 2.0810 - val_accuracy: 0.2500 - val_loss: 2.1625\n",
            "Epoch 32/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.3958 - loss: 1.9174 - val_accuracy: 0.1667 - val_loss: 2.1311\n",
            "Epoch 33/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.3958 - loss: 1.6733 - val_accuracy: 0.0833 - val_loss: 2.3137\n",
            "Epoch 34/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.2917 - loss: 1.7037 - val_accuracy: 0.0833 - val_loss: 2.3634\n",
            "Epoch 35/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.3125 - loss: 1.7037 - val_accuracy: 0.0833 - val_loss: 2.1959\n",
            "Epoch 36/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.3542 - loss: 1.5818 - val_accuracy: 0.0833 - val_loss: 2.0609\n",
            "Epoch 37/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.5000 - loss: 1.5538 - val_accuracy: 0.1667 - val_loss: 2.0190\n",
            "Epoch 38/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.3958 - loss: 1.5812 - val_accuracy: 0.1667 - val_loss: 1.9815\n",
            "Epoch 39/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.5417 - loss: 1.5131 - val_accuracy: 0.0833 - val_loss: 1.9965\n",
            "Epoch 40/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.6042 - loss: 1.4430 - val_accuracy: 0.1667 - val_loss: 2.0778\n",
            "Epoch 41/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.5000 - loss: 1.4575 - val_accuracy: 0.1667 - val_loss: 2.1197\n",
            "Epoch 42/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.5208 - loss: 1.4697 - val_accuracy: 0.2500 - val_loss: 2.0796\n",
            "Epoch 43/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.5000 - loss: 1.4281 - val_accuracy: 0.2500 - val_loss: 2.0111\n",
            "Epoch 44/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.5833 - loss: 1.3820 - val_accuracy: 0.1667 - val_loss: 1.9756\n",
            "Epoch 45/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.6042 - loss: 1.3761 - val_accuracy: 0.0000e+00 - val_loss: 1.9753\n",
            "Epoch 46/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.6042 - loss: 1.3706 - val_accuracy: 0.1667 - val_loss: 1.9881\n",
            "Epoch 47/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7083 - loss: 1.3236 - val_accuracy: 0.1667 - val_loss: 2.0246\n",
            "Epoch 48/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.8125 - loss: 1.2777 - val_accuracy: 0.1667 - val_loss: 2.0785\n",
            "Epoch 49/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7500 - loss: 1.2642 - val_accuracy: 0.1667 - val_loss: 2.1041\n",
            "Epoch 50/50\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7083 - loss: 1.2538 - val_accuracy: 0.1667 - val_loss: 2.0669\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e7015e83820>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.layers import Conv1D, Activation, Flatten, Dense\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "root_path= r'/content/drive/MyDrive/Video_Speech_Actor_06'\n",
        "actors = ['Actor_06']\n",
        "features=[]\n",
        "labels=[]\n",
        "\n",
        "for actor in actors:\n",
        "    file_names = os.listdir(os.path.join(root_path,actor))\n",
        "    for i in range(len(file_names)):\n",
        "                full_path = os.path.join(root_path, actor, file_names[i])\n",
        "                splits= file_names[i].split('.')[0].split('-')\n",
        "                label = splits[2]\n",
        "                modality=splits[0]\n",
        "                if modality=='01':\n",
        "                   raw_audio, sample_rate = librosa.load(full_path, sr=22050, duration=3)\n",
        "                   mfccs=librosa.feature.mfcc(y=raw_audio, sr=22050, n_mfcc=13)\n",
        "                   mfccs = np.mean(mfccs,axis=0)\n",
        "                   features.append(mfccs)\n",
        "                   labels.append(int(label))\n",
        "\n",
        "features = np.asarray(features)\n",
        "labels = np.asarray(labels)\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=7)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "lb = LabelEncoder()\n",
        "lb.fit(np.concatenate((y_train, y_test)))\n",
        "y_train = to_categorical(lb.transform(y_train))\n",
        "y_test = to_categorical(lb.transform(y_test))\n",
        "x_train = np.expand_dims(X_train, axis=2)\n",
        "x_test = np.expand_dims(X_test, axis=2)\n",
        "num_classes = y_train.shape[1]\n",
        "\n",
        "from keras.models import Model\n",
        "from keras import Input\n",
        "\n",
        "inputs = Input(shape=(X_train.shape[1],1))\n",
        "x=Conv1D(32, 5, padding='same')(inputs)\n",
        "x=Conv1D(32, 5, padding='same')(x)\n",
        "x=Activation('relu')(x)\n",
        "x=Conv1D(64, 3)(x)\n",
        "x=Conv1D(64, 3)(x)\n",
        "x=Flatten()(x)\n",
        "x=Dense(num_classes)(x)\n",
        "x=Activation('softmax')(x)\n",
        "model = Model(inputs=inputs, outputs=x)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=50, batch_size=64)"
      ]
    }
  ]
}